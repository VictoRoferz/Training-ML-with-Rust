{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a0991721ddfa2e",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 2: Decision Tree in Rust (with PyO3 & scikit-learn)\n",
    "\n",
    "Welcome to Assignment 2, where youâ€™ll build on your Rust knowledge and explore integrating Python and Rust for AI tasks. You will:\n",
    "\n",
    "1. Implement a Decision Tree classifier from scratch in Rust.\n",
    "2. Compare results to scikit-learnâ€™s Decision Tree using PyO3 calls.\n",
    "\n",
    "**Deliverables**:\n",
    "- A Rust library that implements your decision tree.\n",
    "- A binary (CLI) that can train/test the tree on a CSV dataset.\n",
    "- This notebook (`assignment_2.ipynb`) showing how you generated data, called Rust code, and compared results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e199fc19206df",
   "metadata": {},
   "source": [
    "## Usage of AI Coding Assistant\n",
    "\n",
    "Usage of AI Coding Assistant is permitted to assist in completing the assignment under the following conditions:\n",
    "\n",
    "1. The code suggestions provided by the AI Coding Assistant can be used to understand the Rust programming language and complete the assignment. However, it is not allowed to copy the code produced by the AI Coding Assistant (as it is) and submit it as the solution to the assignment. You should try to understand the code suggestions and write your own code.\n",
    "\n",
    "2. The usage of any AI Coding Assistant must be acknowledged and disclosed in the submission by writing information about the model used, the prompt(s) used to generate the code, and the parts of the code written by the AI Coding Assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db1be64df43e31",
   "metadata": {},
   "source": [
    "## AI Coding Assistant Usage Disclosure\n",
    "\n",
    "In case you used an AI Coding Assistant to help you in completing this assignment, it is required to write a disclosure about the model used, the prompts used to generate the code, and the parts of the code generated by the AI Coding Assistant.\n",
    "\n",
    "**Please note that using AI Coding Assistant would not affect your grade in any way as long as you disclose the required information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa132a225d58cdbe",
   "metadata": {},
   "source": [
    "[# Write your disclosure here if applicable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba7a5f6a7ac6f4",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620eebcf9c6308e1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Verification\n",
    "\n",
    "In this section, youâ€™ll verify your environment, just like in Assignment 1.\n",
    "\n",
    "**Steps/Notes**:\n",
    "- Check if Python, Rust, Cargo, and scikit-learn are installed.\n",
    "- Possibly remind students to set up a new virtual environment for Python.\n",
    "- Mention any required crates: e.g., `[dependencies] pyo3 = \"0.23.4\"`\n",
    "- Make sure to use Python 3.10+ for PyO3 compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0b1a58ce5fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo 1.90.0 (840b83a10 2025-07-30)\n",
      "rustc 1.90.0 (1159e78c4 2025-09-14)\n",
      "Python 3.14.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Obtaining file:///Users/marconms/dev/uni/Training-ML-with-Rust (from -r requirements.txt (line 1))\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: comm==0.2.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 4)) (0.2.3)\n",
      "Collecting contourpy==1.3.3 (from -r requirements.txt (line 5))\n",
      "  Using cached contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 6))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: debugpy==1.8.17 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 7)) (1.8.17)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 8)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.1 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 9)) (2.2.1)\n",
      "Collecting fonttools==4.60.1 (from -r requirements.txt (line 10))\n",
      "  Using cached fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Requirement already satisfied: ipykernel==7.1.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 11)) (7.1.0)\n",
      "Requirement already satisfied: ipython==9.7.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 12)) (9.7.0)\n",
      "Requirement already satisfied: ipython-pygments-lexers==1.1.1 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 13)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 14)) (0.19.2)\n",
      "Collecting joblib==1.5.2 (from -r requirements.txt (line 15))\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jupyter-client==8.6.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 16)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core==5.9.1 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 17)) (5.9.1)\n",
      "Collecting kiwisolver==1.4.9 (from -r requirements.txt (line 18))\n",
      "  Using cached kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting matplotlib==3.10.7 (from -r requirements.txt (line 19))\n",
      "  Using cached matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.2.1 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 20)) (0.2.1)\n",
      "Collecting maturin==1.9.6 (from -r requirements.txt (line 21))\n",
      "  Using cached maturin-1.9.6-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (16 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 22)) (1.6.0)\n",
      "Collecting numpy==2.3.4 (from -r requirements.txt (line 23))\n",
      "  Using cached numpy-2.3.4-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging==25.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 24)) (25.0)\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 25))\n",
      "  Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: parso==0.8.5 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 26)) (0.8.5)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 27)) (4.9.0)\n",
      "Collecting pillow==12.0.0 (from -r requirements.txt (line 28))\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: pip==25.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 29)) (25.3)\n",
      "Requirement already satisfied: platformdirs==4.5.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 30)) (4.5.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.52 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 31)) (3.0.52)\n",
      "Requirement already satisfied: psutil==7.1.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 32)) (7.1.3)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 33)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 34)) (0.2.3)\n",
      "Requirement already satisfied: pygments==2.19.2 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 35)) (2.19.2)\n",
      "Collecting pyparsing==3.2.5 (from -r requirements.txt (line 36))\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 37)) (2.9.0.post0)\n",
      "Collecting pytz==2025.2 (from -r requirements.txt (line 38))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 39)) (27.1.0)\n",
      "Collecting scikit-learn==1.7.2 (from -r requirements.txt (line 41))\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.16.3 (from -r requirements.txt (line 42))\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting seaborn==0.13.2 (from -r requirements.txt (line 43))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 44)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 45)) (0.6.3)\n",
      "Collecting threadpoolctl==3.6.0 (from -r requirements.txt (line 46))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tornado==6.5.2 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 47)) (6.5.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 48)) (5.14.3)\n",
      "Collecting tzdata==2025.2 (from -r requirements.txt (line 49))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.14 in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 50)) (0.2.14)\n",
      "Using cached contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl (273 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl (2.8 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached maturin-1.9.6-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (15.8 MB)\n",
      "Using cached numpy-2.3.4-cp314-cp314-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl (8.6 MB)\n",
      "Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Building wheels for collected packages: rustdt\n",
      "  Building editable for rustdt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rustdt: filename=rustdt-0.1.0-cp314-cp314-macosx_11_0_arm64.whl size=321815 sha256=05d57af2b478b0dfb4573d3e5c885b78fd7f4d264e7f801a6b12bfbc86e409c1\n",
      "  Stored in directory: /private/var/folders/hm/6gnw9yzj0vb_8pl8_wv3g_9m0000gn/T/pip-ephem-wheel-cache-x__54g3m/wheels/f5/40/67/22d77d93757201047a16adb9f1d4c8796dd53a5d0d1f87ad51\n",
      "Successfully built rustdt\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, rustdt, pyparsing, pillow, numpy, maturin, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib, seaborn\n",
      "\u001b[2K  Attempting uninstall: rustdt\n",
      "\u001b[2K    Found existing installation: rustdt 0.1.0\n",
      "\u001b[2K    Uninstalling rustdt-0.1.0:\n",
      "\u001b[2K      Successfully uninstalled rustdt-0.1.0\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18/18\u001b[0m [seaborn]7/18\u001b[0m [seaborn]ib]n]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.7 maturin-1.9.6 numpy-2.3.4 pandas-2.3.3 pillow-12.0.0 pyparsing-3.2.5 pytz-2025.2 rustdt-0.1.0 scikit-learn-1.7.2 scipy-1.16.3 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ðŸ”— Found pyo3 bindings\n",
      "ðŸ Found CPython 3.14 at /Users/marconms/dev/uni/Training-ML-with-Rust/.venv/bin/python\n",
      "\u001b[1m\u001b[32m    Finished\u001b[0m `release` profile [optimized] target(s) in 0.02s\n",
      "ðŸ“¦ Built wheel for CPython 3.14 to /var/folders/hm/6gnw9yzj0vb_8pl8_wv3g_9m0000gn/T/.tmpKBGaSQ/rustdt-0.1.0-cp314-cp314-macosx_11_0_arm64.whl\n",
      "âœï¸ Setting installed package as editable\n",
      "ðŸ›  Installed rustdt-0.1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: rustdt\n",
      "Version: 0.1.0\n",
      "Summary: \n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: /Users/marconms/dev/uni/Training-ML-with-Rust/.venv/lib/python3.14/site-packages\n",
      "Editable project location: /Users/marconms/dev/uni/Training-ML-with-Rust\n",
      "Requires: \n",
      "Required-by: \n",
      "Name: scikit-learn\n",
      "Version: 1.7.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: BSD-3-Clause\n",
      "Location: /Users/marconms/dev/uni/Training-ML-with-Rust/.venv/lib/python3.14/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "!cargo --version\n",
    "!rustc --version\n",
    "!python --version\n",
    "\n",
    "print(\"\\n\" * 3)\n",
    "\n",
    "# Installs dependencies and maturin for pyo3\n",
    "# Assumes that a venv has already been created and sourced\n",
    "%pip install -r requirements.txt\n",
    "!maturin develop --release\n",
    "\n",
    "print(\"\\n\" * 3)\n",
    "\n",
    "# Check Python packages:\n",
    "!pip show rustdt\n",
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554346c3693f4d46",
   "metadata": {},
   "source": [
    "# 2. Implementing a Decision Tree in Rust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982f97e95df15c7",
   "metadata": {},
   "source": [
    "# 2.1. Core requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c058a0804558b64",
   "metadata": {},
   "source": [
    "Implement the following core functionalities for a Decision Tree classifier in a Rust project (not here in the notebook):\n",
    "1. Tree Building: A function (e.g., fit()) that constructs the decision tree from training data.\n",
    "2. Prediction: A function (e.g., predict()) that, given a vector of features, returns a predicted label or probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c11f2da3b3d06",
   "metadata": {},
   "source": [
    "# 3. Comparison with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950d0336f8232be",
   "metadata": {},
   "source": [
    "Implement the similar functions as scikit-learn DecisionTreeClassifier that use your Rust implementation using PyO3 bindings then compare it with scikit-learn performance (runtime for both training and inference) and accuracy. Write code in Python the does the following:\n",
    "1. Load a dataset.\n",
    "2. Run scikit-learn DecisionTreeClassifier on the dataset.\n",
    "3. Run your Rust Decision Tree on the same dataset.\n",
    "4. Store the results.\n",
    "5. Compare the results across implementations and datasets in a table and suitable plots.\n",
    "6. Write a short summary of the comparison.\n",
    "\n",
    "Use the following dataset for comparison (check [here](https://scikit-learn.org/stable/datasets/real_world.html) for loading instructions):\n",
    "- fetch_covtype\n",
    "- adult (use fetch_openml('adult', version=2))\n",
    "- fetch_kddcup99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dcba6066b5d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark configuration:\n",
      "  n_runs: 1\n",
      "  max_samples: 50000\n",
      "  max_depth: 10\n",
      "  min_samples_split: 20\n",
      "  min_samples_leaf: 10\n",
      "\n",
      "Running covtype ...\n",
      "Running adult ...\n",
      "Running kddcup99 ...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_covtype, fetch_openml, fetch_kddcup99\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.tree import DecisionTreeClassifier as SkDecisionTree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "from rustdt import RustDecisionTreeClassifier\n",
    "\n",
    "# Configuration\n",
    "config = dict(\n",
    "    n_runs=1,\n",
    "    max_samples=50000,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    dataset: str\n",
    "    model: str\n",
    "    train_time: float\n",
    "    infer_time: float\n",
    "    accuracy: float\n",
    "\n",
    "\n",
    "def load_covtype():\n",
    "    X, y = fetch_covtype(as_frame=True, return_X_y=True)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_adult():\n",
    "    X, y = fetch_openml(\"adult\", version=2, as_frame=True, return_X_y=True)\n",
    "    return X, y\n",
    "\n",
    "def load_kddcup99():\n",
    "    X, y = fetch_kddcup99(as_frame=True, return_X_y=True)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def preprocess(X_train, X_test):\n",
    "    num_sel = make_column_selector(dtype_include=[\"int64\", \"float64\"])\n",
    "    cat_sel = make_column_selector(dtype_exclude=[\"int64\", \"float64\"])\n",
    "    preproc = ColumnTransformer(\n",
    "        [\n",
    "            (\"num\", \"passthrough\", num_sel),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_sel),\n",
    "        ]\n",
    "    )\n",
    "    X_train = preproc.fit_transform(X_train)\n",
    "    X_test = preproc.transform(X_test)\n",
    "    if sparse.issparse(X_train):\n",
    "        X_train, X_test = X_train.toarray(), X_test.toarray()\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def run_benchmark(\n",
    "    name: str,\n",
    "    loader: Callable[[], tuple],\n",
    "    n_runs: int = 1,\n",
    "    max_samples: int | None = None,\n",
    "    max_depth: int = 10,\n",
    "    min_samples_split: int = 20,\n",
    "    min_samples_leaf: int = 10,\n",
    ") -> List[BenchmarkResult]:\n",
    "    X, y = loader()\n",
    "    if max_samples and len(y) > max_samples:\n",
    "        X = X.sample(n=max_samples, random_state=0)\n",
    "        y = y.loc[X.index] if hasattr(y, \"loc\") else y[:max_samples]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        X_train, X_test, y_train_raw, y_test_raw = train_test_split(\n",
    "            X, y, test_size=0.25, random_state=0,\n",
    "            # stratify=y <- kddcup99 is not suitable for stratification without filtering\n",
    "        )\n",
    "        y_train = LabelEncoder().fit_transform(y_train_raw)\n",
    "        y_test = LabelEncoder().fit(y_train_raw).transform(y_test_raw)\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "\n",
    "        sk = SkDecisionTree(\n",
    "            criterion=\"gini\",\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=0,\n",
    "        )\n",
    "        t0 = time.perf_counter()\n",
    "        sk.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        y_pred = sk.predict(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        results.append(\n",
    "            BenchmarkResult(\n",
    "                name, \"sklearn\", t1 - t0, t2 - t1, accuracy_score(y_test, y_pred)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        rs = RustDecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "        )\n",
    "        t0 = time.perf_counter()\n",
    "        rs.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        y_pred = rs.predict(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        results.append(\n",
    "            BenchmarkResult(\n",
    "                name, \"rust\", t1 - t0, t2 - t1, accuracy_score(y_test, y_pred)\n",
    "            )\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Print config\n",
    "    print(\"Benchmark configuration:\")\n",
    "    for k, v in config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    all_results = []\n",
    "    for name, loader in [\n",
    "        (\"covtype\", load_covtype),\n",
    "        (\"adult\", load_adult),\n",
    "        ('kddcup99', load_kddcup99)\n",
    "    ]:\n",
    "        print(f\"Running {name} ...\")\n",
    "        all_results += run_benchmark(name, loader, **config)\n",
    "\n",
    "    df = pd.DataFrame(r.__dict__ for r in all_results)\n",
    "    summary = (\n",
    "        df.groupby([\"dataset\", \"model\"]).mean(numeric_only=True).reset_index().round(4)\n",
    "    )\n",
    "\n",
    "    print(\"\\nAverage results over\", config[\"n_runs\"], \"runs:\\n\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "    for dataset in summary[\"dataset\"].unique():\n",
    "        dset = summary[summary[\"dataset\"] == dataset]\n",
    "        sk, rs = (\n",
    "            dset[dset[\"model\"] == \"sklearn\"].iloc[0],\n",
    "            dset[dset[\"model\"] == \"rust\"].iloc[0],\n",
    "        )\n",
    "        print(f\"\\nDataset: {dataset}\")\n",
    "        print(\n",
    "            f\"  sklearn: acc={sk.accuracy:.4f}, train={sk.train_time:.3f}s, infer={sk.infer_time:.3f}s\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  rust   : acc={rs.accuracy:.4f}, train={rs.train_time:.3f}s, infer={rs.infer_time:.3f}s\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481add44e8d2270",
   "metadata": {},
   "source": [
    "##### Instructions\n",
    "Before running, please make sure to install the python packages specified in the `requirements.txt` file and compile the project with `!maturin develop --release`. For your convenience, the cell in section 1 of this notebook has been updated with the necessary commands. The commands assume that a virtual environment has already been created and sourced before running the commands.\n",
    "\n",
    "##### Description of the implementation\n",
    "The Rust class `RustDecisionTreeClassifier` exposes the two methods to Python:\n",
    "- fit(x, y): trains the model with the provided dataset and labels\n",
    "- predict(x): predicts the label for the provided datapoints\n",
    "\n",
    "The implementation wraps a parallel Rust decision tree using a thin Python interface built with PyO3. Data is passed as NumPy arrays for zero-copy conversion into Rustâ€™s ndarray types. Heavy computation runs fully in Rust, parallelized with Rayon, while Python's Global Interpeter Lock is released as soon as possible to allow other Python threads to run if necesary.\n",
    "\n",
    "We relied heavility on scikit-learn's own `DecisionTreeClassifier` for our implementation, due to the limited time given for the task and the wish to achieve an efficient implementation of the classifier.\n",
    "\n",
    "##### Interpretation of the benchmark results\n",
    "- The Rust classifier matches scikit-learnâ€™s accuracy almost exactly and consistently.\n",
    "- Training and inference are about ~2â€“4Ã— faster in out Rust implementation\n",
    "- The implementation and the achieved performance gains clearly demonstrate the advantages of choosing Rust for resource-intensive ML application, both in training and inference. Such a big differnce could save a lot of time and resources for the training of bigger AI models.\n",
    "\n",
    "##### Resources utilized\n",
    "- Pyo3's docs: https://pyo3.rs/v0.27.1/\n",
    "- scikit-learn's DecisionTreeClassifier class: https://github.com/scikit-learn/scikit-learn/blob/4e2f1b7094d27ddca17bee1eee61af2ab20a7d23/sklearn/tree/_tree.pxd\n",
    "\n",
    "#### Testing environment\n",
    "OS: macOS 26.0.1 (25A362)\\\n",
    "cargo 1.90.0 (840b83a10 2025-07-30)\\\n",
    "rustc 1.90.0 (1159e78c4 2025-09-14)\\\n",
    "Python 3.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7be1e8e73e1eed",
   "metadata": {},
   "source": [
    "# 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a21afd312db944",
   "metadata": {},
   "source": [
    "**What to submit**: (all in one zip file named: `EffAIRust_assignment_2_Team_[TeamID].zip`):\n",
    "1. Your completed Rust project (with `Cargo.toml`, `src/`, tests, etc.).\n",
    "2. This notebook (`assignment_2.ipynb`), so we can see your test results.\n",
    "\n",
    "Submit the assignment as a ZIP file to Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
